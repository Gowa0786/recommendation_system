{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669e52fb-a24c-467f-baae-e2e8ec6de135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00141d1c-f346-49a0-affe-e922b4eff5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795415</th>\n",
       "      <td>2021-10-01 06:01:40</td>\n",
       "      <td>59784</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988115</th>\n",
       "      <td>2021-10-01 06:01:40</td>\n",
       "      <td>73455</td>\n",
       "      <td>2671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295082</th>\n",
       "      <td>2021-10-01 06:01:52</td>\n",
       "      <td>21049</td>\n",
       "      <td>1453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  user_id  post_id  target\n",
       "795415  2021-10-01 06:01:40    59784      307       1\n",
       "988115  2021-10-01 06:01:40    73455     2671       1\n",
       "295082  2021-10-01 06:01:52    21049     1453       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_clean = pd.read_csv('df_final_clean.csv')\n",
    "df_final_clean_sorted = df_final_clean.sort_values(by='timestamp')\n",
    "df_final_clean_sorted[['timestamp', 'user_id', 'post_id', 'target']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9672f08-de44-4c17-93d1-d50df73e5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_clean_sorted['topic_hour'] = df_final_clean_sorted['topic_code'] * df_final_clean_sorted['hour_cos']\n",
    "df_final_clean_sorted['age_topic'] = df_final_clean_sorted['age_category'] * df_final_clean_sorted['topic_code']\n",
    "df_final_clean_sorted['weekend_hour'] = (df_final_clean_sorted['dow_sin'] > 0) * df_final_clean_sorted['hour_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5aa81c6-51ae-4eec-9e40-c16cb8fd1460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2316912 entries, 795415 to 706797\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   timestamp            object \n",
      " 1   user_id              int64  \n",
      " 2   post_id              int64  \n",
      " 3   target               int64  \n",
      " 4   age_category         int64  \n",
      " 5   gender               int64  \n",
      " 6   exp_group            int64  \n",
      " 7   hour_sin             float64\n",
      " 8   hour_cos             float64\n",
      " 9   dow_sin              float64\n",
      " 10  dow_cos              float64\n",
      " 11  topic_code           int64  \n",
      " 12  topic_movie          float64\n",
      " 13  topic_politics       float64\n",
      " 14  topic_sport          float64\n",
      " 15  topic_business       float64\n",
      " 16  topic_entertainment  float64\n",
      " 17  topic_tech           float64\n",
      " 18  post_embed_0         float64\n",
      " 19  post_embed_1         float64\n",
      " 20  topic_hour           float64\n",
      " 21  age_topic            int64  \n",
      " 22  weekend_hour         float64\n",
      "dtypes: float64(14), int64(8), object(1)\n",
      "memory usage: 424.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final_clean_sorted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec16778a-81af-4ac1-a2a6-7f27ec285b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ó–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç–∞:\n",
      "age_topic\n",
      "0     482519\n",
      "1     109855\n",
      "2     109096\n",
      "3     283737\n",
      "4     165053\n",
      "5     111592\n",
      "6     173936\n",
      "8      83972\n",
      "9     168076\n",
      "10     75879\n",
      "12    227878\n",
      "15    134068\n",
      "16     33670\n",
      "18     35924\n",
      "20     62188\n",
      "24     20409\n",
      "25     20761\n",
      "30     14867\n",
      "36      3432\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n–ó–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç–∞:\")\n",
    "print(df_final_clean_sorted['age_topic'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a51895-275a-412f-9d95-c74a41fe9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_at_5_fast(preds, train_data):\n",
    "    \"\"\"–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è Hitrate@5.\"\"\"\n",
    "    y_true = train_data.get_label()\n",
    "    groups = train_data.get_group()\n",
    "    \n",
    "    hitrates = []\n",
    "    ptr = 0\n",
    "    \n",
    "    for group_size in groups:\n",
    "        if group_size >= 5:  # –ï—Å–ª–∏ –≤ –≥—Ä—É–ø–ø–µ —Ö–æ—Ç—è –±—ã 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "            # –ë–µ—Ä–µ–º –∏–Ω–¥–µ–∫—Å—ã top-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ –≥—Ä—É–ø–ø–µ\n",
    "            group_preds = preds[ptr:ptr + group_size]\n",
    "            group_true = y_true[ptr:ptr + group_size]\n",
    "            \n",
    "            # –ò—Å–ø–æ–ª—å–∑—É–µ–º argsort –≤–º–µ—Å—Ç–æ argpartition\n",
    "            top_5_idx = np.argsort(-group_preds)[:5]\n",
    "            hit = 1 if np.any(group_true[top_5_idx] == 1) else 0\n",
    "            hitrates.append(hit)\n",
    "        elif group_size > 0:\n",
    "            # –î–ª—è –≥—Ä—É–ø–ø –º–µ–Ω—å—à–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—á–∏—Ç–∞–µ–º –ø–æ –≤—Å–µ–º\n",
    "            group_true = y_true[ptr:ptr + group_size]\n",
    "            hit = 1 if np.any(group_true == 1) else 0\n",
    "            hitrates.append(hit)\n",
    "        \n",
    "        ptr += group_size\n",
    "    \n",
    "    return 'hitrate@5', np.mean(hitrates), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b3397d-0fcf-425e-b977-3b6a873744b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ 14 —á–∏—Å–ª–æ–≤—ã—Ö —Ñ–∏—á–µ–π\n",
      "============================================================\n",
      "–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø LAMBDARANK\n",
      "============================================================\n",
      "–ü–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏: train=1869653 –∑–∞–ø–∏—Å–µ–π, 163105 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "                 test=447259 –∑–∞–ø–∏—Å–µ–π, 134462 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "\n",
      "–†–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø train: [ 8 19 19  4  5]... (–ø–µ—Ä–≤—ã–µ 5)\n",
      "–í—Å–µ–≥–æ –≥—Ä—É–ø–ø –≤ train: 163105\n",
      "–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã: 11.5\n",
      "\n",
      "============================================================\n",
      "–°–û–ó–î–ê–ù–ò–ï LIGHTGBM DATASET\n",
      "============================================================\n",
      "–°–æ–∑–¥–∞–Ω train Dataset: 1869653 —Å—Ç—Ä–æ–∫, 163105 –≥—Ä—É–ø–ø\n",
      "–°–æ–∑–¥–∞–Ω valid Dataset: 447259 —Å—Ç—Ä–æ–∫, 134462 –≥—Ä—É–ø–ø\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# ============================================================================\n",
    "#  0. –ó–ê–ì–†–£–ó–ö–ê –ò –°–ü–õ–ò–¢\n",
    "# ============================================================================\n",
    "\n",
    "df = df_final_clean_sorted.copy()\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "split_time = pd.Timestamp(\"2021-12-12 00:59:05.600000\")\n",
    "\n",
    "df_train = df[df['timestamp'] < split_time].copy()\n",
    "df_test = df[df['timestamp'] >= split_time].copy()\n",
    "\n",
    "# –§–∏—á–∏\n",
    "exclude = ['timestamp', 'user_id', 'post_id', 'target']\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude]\n",
    "\n",
    "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö\n",
    "numeric_cols = df_train.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = ['age_category', 'gender', 'topic_code', 'exp_group', 'age_topic',]\n",
    "num_cols = [c for c in numeric_cols if c not in cat_cols and c not in exclude]\n",
    "\n",
    "# –ë—ã—Å—Ç—Ä–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "if num_cols:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df_train[num_cols] = scaler.fit_transform(df_train[num_cols])\n",
    "    df_test[num_cols] = scaler.transform(df_test[num_cols])\n",
    "    print(f\"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ {len(num_cols)} —á–∏—Å–ª–æ–≤—ã—Ö —Ñ–∏—á–µ–π\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø LAMBDARANK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø LAMBDARANK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1.1 –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ user_id (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!)\n",
    "df_train = df_train.sort_values('user_id').reset_index(drop=True)\n",
    "df_test = df_test.sort_values('user_id').reset_index(drop=True)\n",
    "\n",
    "print(f\"–ü–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏: train={len(df_train)} –∑–∞–ø–∏—Å–µ–π, {df_train['user_id'].nunique()} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "print(f\"                 test={len(df_test)} –∑–∞–ø–∏—Å–µ–π, {df_test['user_id'].nunique()} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "\n",
    "# 1.2 –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n",
    "train_group_sizes = df_train.groupby('user_id').size().values\n",
    "test_group_sizes = df_test.groupby('user_id').size().values\n",
    "\n",
    "print(f\"\\n–†–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø train: {train_group_sizes[:5]}... (–ø–µ—Ä–≤—ã–µ 5)\")\n",
    "print(f\"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø –≤ train: {len(train_group_sizes)}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã: {train_group_sizes.mean():.1f}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
    "assert len(train_group_sizes) == df_train['user_id'].nunique()\n",
    "assert len(test_group_sizes) == df_test['user_id'].nunique()\n",
    "\n",
    "\n",
    "# 1.4 –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏\n",
    "categorical_cols = ['age_category', 'gender', 'topic_code', 'exp_group', 'age_topic',]\n",
    "for col in categorical_cols:\n",
    "    df_train[col] = df_train[col].astype('category')\n",
    "    df_test[col] = df_test[col].astype('category')\n",
    "\n",
    "# 1.5 –û—Ç–¥–µ–ª—è–µ–º X, y\n",
    "X_train = df_train[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "y_train = df_train['target'].values\n",
    "y_test = df_test['target'].values\n",
    "\n",
    "# ============================================================================\n",
    "# 2. –°–û–ó–î–ê–ù–ò–ï DATASET –°  –ì–†–£–ü–ü–ê–ú–ò\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–°–û–ó–î–ê–ù–ò–ï LIGHTGBM DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: group=group_sizes, –∞ –Ω–µ group=GroupBy –æ–±—ä–µ–∫—Ç!\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,  # DataFrame —Å category —Ç–∏–ø–∞–º–∏\n",
    "    label=y_train,\n",
    "    group=train_group_sizes,  # –ú–ê–°–°–ò–í —Ä–∞–∑–º–µ—Ä–æ–≤ –≥—Ä—É–ø–ø!\n",
    "    categorical_feature=categorical_cols,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "valid_data = lgb.Dataset(\n",
    "    X_test,\n",
    "    label=y_test,\n",
    "    group=test_group_sizes,  # –ú–ê–°–°–ò–í —Ä–∞–∑–º–µ—Ä–æ–≤ –≥—Ä—É–ø–ø!\n",
    "    reference=train_data,  # –í–∞–∂–Ω–æ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "    categorical_feature=categorical_cols,\n",
    "    free_raw_data=False\n",
    ")\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω train Dataset: {len(X_train)} —Å—Ç—Ä–æ–∫, {len(train_group_sizes)} –≥—Ä—É–ø–ø\")\n",
    "print(f\"–°–æ–∑–¥–∞–Ω valid Dataset: {len(X_test)} —Å—Ç—Ä–æ–∫, {len(test_group_sizes)} –≥—Ä—É–ø–ø\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9364047-40d1-47cb-8fca-4294ca65f472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ negative:positive = 5.1:1\n",
      "\n",
      "============================================================\n",
      "–ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï LAMBDARANK\n",
      "============================================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid's ndcg@5: 0.868313\tvalid's ndcg@10: 0.878286\tvalid's hitrate@5: 0.49231\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid's ndcg@5: 0.86827\tvalid's ndcg@10: 0.878207\tvalid's hitrate@5: 0.492437\n",
      "\n",
      "============================================================\n",
      "‚úÖ LAMBDARANK –û–ë–£–ß–ï–ù!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. –ü–ê–†–ê–ú–ï–¢–†–´ LAMBDARANK\n",
    "# ============================================================================\n",
    "\n",
    "# –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å–∞\n",
    "positive_count = y_train.sum()\n",
    "negative_count = len(y_train) - positive_count\n",
    "scale_pos_weight = negative_count / positive_count  # ‚âà 4.0\n",
    "\n",
    "print(f\"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ negative:positive = {scale_pos_weight:.1f}:1\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [5, 10],\n",
    "    \n",
    "    # –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê\n",
    "    'scale_pos_weight': scale_pos_weight,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞\n",
    "    \n",
    "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã lambdarank\n",
    "    'lambdarank_truncation_level': 10,\n",
    "    'lambdarank_norm': True,\n",
    "    'label_gain': [0, 1],\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—É—Å–∏–ª–∏–ª —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é)\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': max(20, int(20 * scale_pos_weight / 10)),  # –£–≤–µ–ª–∏—á–∏–ª\n",
    "    'max_depth': 7,  \n",
    "    \n",
    "    # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    'lambda_l1': 0.15,\n",
    "    'lambda_l2': 0.15,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 5,\n",
    "    \n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 4. –û–ë–£–ß–ï–ù–ò–ï\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï LAMBDARANK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[valid_data],\n",
    "    valid_names=['valid'],\n",
    "    feval=hitrate_at_5_fast,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ LAMBDARANK –û–ë–£–ß–ï–ù!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86933a71-4a8c-41e5-8342-bc596bfbcf6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...\n",
      "   –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: lgbm_lambdarank_model.txt\n",
      "\n",
      "4. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\n",
      "\n",
      "–¢–û–ü-10 –í–ê–ñ–ù–´–• –§–ò–ß–ï–ô (–ø–æ gain):\n",
      "============================================================\n",
      "            feature  importance_gain  importance_split\n",
      "          age_topic     13174.302507                82\n",
      "       age_category     10953.729088                95\n",
      "         topic_code      9459.585524                80\n",
      "         topic_hour      5206.247795                52\n",
      "     topic_politics      2894.606594                58\n",
      "           hour_cos      2850.715607                31\n",
      "        topic_sport      2563.668386                62\n",
      "       post_embed_1      2025.047792                44\n",
      "        topic_movie      2000.863907                48\n",
      "       post_embed_0      1453.826305                40\n",
      "           hour_sin      1149.651989                25\n",
      "       weekend_hour       963.130211                14\n",
      "topic_entertainment       818.134007                26\n",
      "     topic_business       673.745003                25\n",
      "          exp_group       380.377602                14\n",
      "         topic_tech       350.490398                13\n",
      "            dow_sin       223.288401                 8\n",
      "            dow_cos        80.873199                 3\n",
      "             gender         0.000000                 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò\n",
    "# ============================================================================\n",
    "print(\"\\n3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...\")\n",
    "\n",
    "model.save_model('lgbm_lambdarank_model.txt')\n",
    "print(f\"   –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: lgbm_lambdarank_model.txt\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
    "# ============================================================================\n",
    "print(\"\\n4. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "\n",
    "# –í–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π\n",
    "importance_gain = model.feature_importance(importance_type='gain')\n",
    "importance_split = model.feature_importance(importance_type='split')\n",
    "\n",
    "# –¢–æ–ø-20 —Ñ–∏—á–µ–π\n",
    "importance_data = []\n",
    "for i, name in enumerate(feature_cols):\n",
    "    importance_data.append({\n",
    "        'feature': name,\n",
    "        'importance_gain': importance_gain[i],\n",
    "        'importance_split': importance_split[i]\n",
    "    })\n",
    "\n",
    "importance_df = pd.DataFrame(importance_data)\n",
    "importance_df = importance_df.sort_values('importance_gain', ascending=False)\n",
    "\n",
    "print(\"\\n–¢–û–ü –í–ê–ñ–ù–´–• –§–ò–ß–ï–ô (–ø–æ gain):\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.head(40).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b441dba-0014-4681-b7ad-b81c8a004302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "414d6270-4e5d-4365-982d-a35ca438c780",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "\"\"\"\n",
    "\n",
    "#–ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –∫—É—Ä—Å–∞\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "\n",
    "def safe_chunked_upload(df, table_name, chunk_size=50000):  # –£–º–µ–Ω—å—à–∏–ª —á–∞–Ω–∫\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    total_chunks = total_rows // chunk_size + 1\n",
    "    print(f\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows:,}, —á–∞–Ω–∫–æ–≤: {total_chunks}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, start in enumerate(range(0, total_rows, chunk_size)):\n",
    "        chunk_start_time = time.time()\n",
    "        end = min(start + chunk_size, total_rows)\n",
    "        chunk = df.iloc[start:end]\n",
    "        \n",
    "        success = False\n",
    "        retries = 3  # 3 –ø–æ–ø—ã—Ç–∫–∏\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                # –ö–ê–ñ–î–´–ô –†–ê–ó –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ\n",
    "                engine = create_engine(\n",
    "                    \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "                    \"postgres.lab.karpov.courses:6432/startml\"\n",
    "                )\n",
    "                \n",
    "                with engine.begin() as conn:\n",
    "                    if start == 0 and attempt == 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏\n",
    "                        chunk.to_sql(\n",
    "                            table_name, \n",
    "                            con=conn, \n",
    "                            if_exists='replace', \n",
    "                            index=False,\n",
    "                            chunksize=10000  # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π chunksize\n",
    "                        )\n",
    "                    else:\n",
    "                        chunk.to_sql(\n",
    "                            table_name, \n",
    "                            con=conn, \n",
    "                            if_exists='append', \n",
    "                            index=False,\n",
    "                            chunksize=10000\n",
    "                        )\n",
    "                \n",
    "                engine.dispose()\n",
    "                success = True\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"–ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{retries} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}\")\n",
    "                time.sleep(10 * (attempt + 1))  # –£–≤–µ–ª–∏—á–∏–≤–∞—é—â–∞—è—Å—è –ø–∞—É–∑–∞\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"‚ùå –ß–∞–Ω–∫ {i+1} –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫\")\n",
    "            return False\n",
    "        \n",
    "        chunk_time = time.time() - chunk_start_time\n",
    "        \n",
    "        print(f\"‚úÖ –ß–∞–Ω–∫ {i+1}/{total_chunks} –∑–∞–ø–∏—Å–∞–Ω ({end:,}/{total_rows:,} —Å—Ç—Ä–æ–∫)\")\n",
    "        print(f\"   ‚è±Ô∏è –í—Ä–µ–º—è —á–∞–Ω–∫–∞: {chunk_time:.1f} —Å–µ–∫\")\n",
    "        print(f\"   üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {(end/total_rows*100):.1f}%\")\n",
    "        \n",
    "        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏\n",
    "        if i < total_chunks - 1:\n",
    "            time.sleep(2)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã!\")\n",
    "    print(f\"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n",
    "if safe_chunked_upload(df_final_clean_sorted, 'g_seregin_lbm4969_features', 70000):\n",
    "    print(\"üéâ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã!\")\n",
    "else:\n",
    "    print(\"üí• –ó–∞–ø–∏—Å—å –ø—Ä–µ—Ä–≤–∞–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ffc373-ad12-43d8-a8c8-90c47a7a2bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56311078-e2fe-414f-b812-5a854a35259f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
